{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tanu-N-Prabhu/Python/blob/master/Predicting_PewDiePie's_daily_subscribers_using_Machine_Learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKiTLCkv3QAL"
   },
   "source": [
    "# Predicting PewDiePie's daily subscribers using Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hk9wZqcdcBU3"
   },
   "source": [
    "## Let us understand how to predict PewDiePie's daily subscribers using Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDcs-uzN4ARg"
   },
   "source": [
    "![alt text](https://o.aolcdn.com/images/dims?quality=85&image_uri=https%3A%2F%2Fo.aolcdn.com%2Fimages%2Fdims%3Fcrop%3D2999%252C2041%252C0%252C63%26quality%3D85%26format%3Djpg%26resize%3D1600%252C1089%26image_uri%3Dhttp%253A%252F%252Fo.aolcdn.com%252Fhss%252Fstorage%252Fmidas%252Fad4588edcab1d7fb3fcba1779e920b12%252F205651508%252Fauthormedia-personality-pewdiepie-poses-for-a-photo-at-an-book-for-picture-id494847828%26client%3Da1acac3e1b3290917d92%26signature%3D9f9196520c3836b1499e32e6aefbec05a47d1a0e&client=amp-blogside-v2&signature=cd9b8f96b7ccbf8b8546edf04924e2f3d7f95f7a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgBXadKwcEH-"
   },
   "source": [
    "[PewDiePie](https://www.youtube.com/channel/UC-lHJZR3Gqxm24_Vd_AJ5Yw) is a Swedish YouTuber and has 100 million subscribers on YouTube (He is my favorite). He gains thousands of subscribers every day, so I thought of writing a tutorial about his gain in subscribers. So I wanted to show you guys a practical implementation of Machine Learning's Linear Regression Algorithm. Here we can apply linear regression to predict his daily YouTube subscribers. I will guide you guys throughout this tutorial how to do so. I will not explain the theory behind linear regression algorithms, because according to me the theory is not so important only the implementation is very important, because you need to know how and where to apply the algorithm. However, I will encourage you to go through some theory online, one of the best articles is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dn8YhN-scLMa"
   },
   "source": [
    "[Linear Regression](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "we8BcmN4cT4K"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06TB7JClcRDd"
   },
   "source": [
    "# Let's get started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXsle1AO4g9D"
   },
   "source": [
    "## The Steps that we are going to follow to complete this implementation is as follows:\n",
    "\n",
    "\n",
    "1. Importing the necessary libraries.\n",
    "2. Reading the dataset from the CSV file.\n",
    "3. Splitting the dataset into independent (x) and dependent (y) variables.\n",
    "4. Dividing the complete dataset into training and testing dataset.\n",
    "5. Implement our classifier based on simple linear regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QIKnypQ4yf6"
   },
   "source": [
    "## 1: Importing the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHO2ONivcdr7"
   },
   "source": [
    "\n",
    "1. numpy\n",
    "2. pandas \n",
    "3. sklearn.linear\n",
    "4. sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qIOcrutcisM"
   },
   "source": [
    "**Numpy:** The reason I am using the numpy library is that in the tutorial's ending I'm rounding off some values to get more accurate results. To invoke the round method, I need to import numpy library. To read the official documentation of numpy library visit the link below:\n",
    "\n",
    "[Numpy](https://numpy.org/devdocs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EB0sFhJMco77"
   },
   "source": [
    "**Pandas:** As you know that I am using the PewDiePie's data from YouTube, I need to store them in some form of a data frame, to store the data in a data frame I am using pandas data frame, it's very easy and interesting to use pandas data frame. To read the official documentation of pandas library visit the link below:\n",
    "\n",
    "[Pandas:](https://pandas.pydata.org/pandas-docs/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRHDyYO0c0PB"
   },
   "source": [
    "**Sklearn.linear:** As you know that by now I'm using Linear Regression algorithm to predict the data, I need to import the linear regression library, but you cannot directly import linear regression library, although you need to import sci-kit learn with the help of that you can access linear regression library. That is the reason I'm using sklearn.linear. To read the official documentation of the library visit the link below:\n",
    "\n",
    "[Sklearn.Linear:](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOQieT2_c7J3"
   },
   "source": [
    "**sklearn.model_selection:** If you are implementing linear regression to predict the data, it is often a good practice to divide the data into training and testing data, only then your predicted data would be a lot more accurate. To do this, you need to import model_selection library from scikit learn. To read the official documentation visit the link below:\n",
    "\n",
    "[Sklearn.model_selection:](https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLSPsRXCdDsf"
   },
   "source": [
    "A quick note to import any library in python all you have to do is just say \"import keyword\" the keyword can be any name of the library such as pandas, numpy and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7EyNMHgdFlR"
   },
   "source": [
    "**Importing the required libraries for this tutorial is as shown below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXxoA2qYodHf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DmmPmnXYdJgQ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isr5LvvD5CBt"
   },
   "source": [
    "## 2. Reading the dataset from the CSV file.\n",
    "\n",
    "I have stored the PewDiePie's subscriber data in a CSV format in Kaggle. Kaggle is a place where people all around the world publish and store the data set. Here I have stored the data in a CSV (Comma Separated Value) format. To download the data set check the link below:\n",
    "\n",
    "[Data-set: ](https://www.kaggle.com/tanuprabhu/pewdiepies-subscribers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t448SXOPdXiE"
   },
   "source": [
    "You can download the data set by clicking the download option. To get the data into a format in python,  you have to use pandas data frame. Now before that you have to load the data into your notebook (I'm using [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb) to type all my python code), there are multiple ways to load the data into the notebook available online, but the easiest way is in [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb) at the left-hand side of the notebook, you will find a \">\"(greater than symbol). When you click that you will find a tab with three options, you just have to select Files. Then you c an easily upload your file with the help of the Upload option. No need to mount to the google drive or use any specific libraries just upload the data set and your job is done. One thing to remember in this step is that uploaded files will get deleted when this runtime is recycled. This is how I got the data set into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "2xFG4Qu0oYcg",
    "outputId": "f4e73088-6d01-4cb5-e60c-5f8ba6bebf35"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PewDiePie.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-99c32a7811cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Storing the data in a pandas data frame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PewDiePie.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PewDiePie.csv'"
     ]
    }
   ],
   "source": [
    "# Storing the data in a pandas data frame.\n",
    "\n",
    "df = pd.read_csv(\"PewDiePie.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HoKlXL8fdpLG"
   },
   "source": [
    "As you can see the above data set contains two columns, data, and subscribers. I know the date column seems confusing don't worry and think more about it, it's just stored the first day of the May 2019 (like May 1, May 2, and more). And the subscriber's column contains all the subscribers of PewDiePie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mf4WrSsdyds"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfzJVXEg6GcA"
   },
   "source": [
    "## 3. Splitting the dataset into independent (x) and dependent (y) variables.\n",
    "\n",
    "Before dividing the data set into the train and test data, you need to tell what are dependent and independent variables only then you can divide later. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J58qvQgHohTO"
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K2egu9Tzdu5b"
   },
   "source": [
    "Here the 'x' value comprises the data and the 'y' value comprises the subscribers, and iloc is used to get the values from a data frame. The reason I have used [:,: -1] is because I needed the second last column from the data frame, and the [:1] gives me the last column of the data frame. You can print the value for confirmation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2RXVy_6edwu0"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqXZivtF5eqI"
   },
   "source": [
    "## 4. Dividing the complete dataset into training and testing dataset.\n",
    "\n",
    "To get a good prediction, divide the data into training and testing data, it is because as the name suggests you will train few data points and test few data points, and keep on doing that unless you get good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqWDNBdoonpq"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KV04urq5d4CM"
   },
   "source": [
    "Here both the 'x' and the 'y' variables are divided into training and testing data, as seen in the above code snippet the size of the test data is 0.3 or 30% and the rest is 70% (training data), random_state is the seed used by the random number generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8s8rSDod5Sv"
   },
   "source": [
    "Note: Try printing the training values of both x and y, then you will understand what I'm talking about. **HINT: print(x_test)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNbahSRkd9gu"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHlXMd-b6a-x"
   },
   "source": [
    "## 5. Implement our classifier based on simple linear regression.\n",
    "\n",
    "\n",
    "This is one of the most important because this is where we apply the linear regression algorithm, to do this we have to feed the trained the tested values to the actual algorithm, by doing so we can predict the subscribers. To do this follow the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FEmJPJgJo__u",
    "outputId": "3c26e919-d1c0-4341-cf20-376b8f7f7679"
   },
   "outputs": [],
   "source": [
    "simplelinearRegression = LinearRegression()\n",
    "simplelinearRegression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0rktK1ceCUO"
   },
   "source": [
    "Here in the above code, we are calling the Linear Regression function and then we are trying to fit the model by-passing the trained values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCg27hf7pBq4"
   },
   "outputs": [],
   "source": [
    "y_predict = simplelinearRegression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xnQ33ZBpDK8"
   },
   "outputs": [],
   "source": [
    "predict = pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "oA0Y0xKkAPu9",
    "outputId": "45981b44-58ce-4007-e10e-5db524c1ee0f"
   },
   "outputs": [],
   "source": [
    "predict.apply(np.round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1NAJb61eFzV"
   },
   "source": [
    "And then we need to predict those values using then predict method, for this we need to pass the tested value of the 'x' variable, by doing so we get the predicted values (subscribers). And the next line of code is just conversion, this is because the y_predict is of type numpy array, so we need to convert this into a data frame only then we can apply the round function. Now the variable predict contains all the predicted subscribers as seen above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oRdwUnZeKpu"
   },
   "source": [
    "Later I will put the data in a while loop to get it in an actual format, don't worry its just a print statement with the predicted values you will get it once you trace it back down:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLj2mNxIeMcm"
   },
   "source": [
    "This is how the predict function can predict the subscribers, the subscribers returned by the predict function is accurate. Below given is the social blade statistics, you can compare the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "uPDWN4J9pEn-",
    "outputId": "77cdf801-bcc6-4587-d4cc-c972cbf2514b"
   },
   "outputs": [],
   "source": [
    "i = 21\n",
    "while i <= 28:\n",
    "  print(\"Total number of increase in subscribers on May %d ==>\" %(i) , int(simplelinearRegression.predict([[i]])))\n",
    "  i= i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnc5EQIQgHYf"
   },
   "source": [
    "<a href=\"http://www.freeimagehosting.net/commercial-photography/\"><img src=\"https://i.imgur.com/gGMEf5i.png\" alt=\"Commercial Photography\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wX-sCmEMeQDV"
   },
   "source": [
    "As seen below when you compare the results of the predicted values with the actual subscriber from the above got by Social Blade, the results are almost same except here and there a few more or less subscriber can be found, but that's OK the machine learning cannot predict 100% accurately. Hence this is how you can use Machine Learning Algorithms to predict the daily subscribers of PewDiePie. If you have any doubt about the code, the comment section is all yours. Contact me for doubts only. Thank you guys for reading my article. Bye, start practicing the code and see you next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PcBDl5lbeS5j"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Predicting PewDiePie's daily subscribers using Machine Learning..ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
